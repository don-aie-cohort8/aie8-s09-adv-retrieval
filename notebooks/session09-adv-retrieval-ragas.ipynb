{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval Evaluations - generating RAGAS Golden Testsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library\n",
        "import getpass\n",
        "import os\n",
        "# import openai\n",
        "\n",
        "# Third-party packages\n",
        "# LangChain\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "# RAGAS\n",
        "# from ragas.embeddings import OpenAIEmbeddings # not available in 0.2.10\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.testset import TestsetGenerator\n",
        "from ragas.testset.graph import KnowledgeGraph, Node, NodeType\n",
        "from ragas.testset.persona import Persona\n",
        "from ragas.testset.synthesizers.single_hop.specific import (\n",
        "    SingleHopSpecificQuerySynthesizer,\n",
        ")\n",
        "from ragas.testset.transforms import (\n",
        "    HeadlinesExtractor,\n",
        "    HeadlineSplitter,\n",
        "    KeyphrasesExtractor,\n",
        "    apply_transforms,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
        "# openai_client = openai.OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the source documents\n",
        "\n",
        "- use the LangChain CSVLoader to load the source documents\n",
        "- specify the metadata columns that will go into the metadata field\n",
        "- any other columns will go into the page_content field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### our initial custom approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the effect of this is that we end up with an empty page_content property\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"../data/Projects_with_Domains.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Project Title\",\n",
        "      \"Project Domain\",\n",
        "      \"Secondary Domain\",\n",
        "      \"Description\",\n",
        "      \"Judge Comments\",\n",
        "      \"Score\",\n",
        "      \"Project Name\",\n",
        "      \"Judge Score\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "ragas_usecase_data_attempt_1 = loader.load()\n",
        "\n",
        "# original code focused on populating the page_content only with the description\n",
        "# below I'm adding additional columns to improve RAGAS golden testset generation\n",
        "# QUESTION 1:  if the metadata content duplicates the page_content, is it really metadata?\n",
        "# QUESTION 2:  what does the structure of the original dataset tell us about the nature of it?  (is it structured or unstructured?)\n",
        "\n",
        "for doc in ragas_usecase_data_attempt_1:\n",
        "    title = doc.metadata.get(\"Project Title\", \"\")\n",
        "    domain = doc.metadata.get(\"Project Domain\", \"\")\n",
        "    secondary = doc.metadata.get(\"Secondary Domain\", \"\")\n",
        "    desc = doc.metadata.get(\"Description\", \"\")\n",
        "\n",
        "    doc.page_content = f\"{title}\\nDomain: {domain}\\nSecondary Domain: {secondary}\\nDescription: {desc}\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of documents\n",
        "len(ragas_usecase_data_attempt_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '../data/Projects_with_Domains.csv', 'row': 0, 'Project Title': 'InsightAI 1', 'Project Domain': 'Security', 'Secondary Domain': 'Finance / FinTech', 'Description': 'A low-latency inference system for multimodal agents in autonomous systems.', 'Judge Comments': 'Technically ambitious and well-executed.', 'Score': '85', 'Project Name': 'Project Aurora', 'Judge Score': '9.5'}, page_content='InsightAI 1\\nDomain: Security\\nSecondary Domain: Finance / FinTech\\nDescription: A low-latency inference system for multimodal agents in autonomous systems.')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# content of the first document\n",
        "ragas_usecase_data_attempt_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# length of the first document's page_content\n",
        "len(ragas_usecase_data_attempt_1[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### revert to more of a standard approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# standard approach of using LangChain loaders\n",
        "# everything that is not specified in metadata_columns goes into the page_content context\n",
        "\n",
        "ragas_loader = CSVLoader(\n",
        "    file_path=\"../data/Projects_with_Domains.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Judge Comments\",\n",
        "      \"Score\",\n",
        "      \"Project Name\",\n",
        "      \"Judge Score\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "ragas_usecase_data = ragas_loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of documents\n",
        "len(ragas_usecase_data_attempt_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': '../data/Projects_with_Domains.csv', 'row': 0, 'Judge Comments': 'Technically ambitious and well-executed.', 'Score': '85', 'Project Name': 'Project Aurora', 'Judge Score': '9.5'}, page_content='Project Title: InsightAI 1\\nProject Domain: Security\\nSecondary Domain: Finance / FinTech\\nDescription: A low-latency inference system for multimodal agents in autonomous systems.')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# content of the first document\n",
        "ragas_usecase_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "176"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# length of the first document's page_content\n",
        "len(ragas_usecase_data[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAGAS Golden Testset Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using the Vanilla Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Documents appears to be too short (ie 100 tokens or less). Please provide longer documents.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m golden_dataset_attempt_1 = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mragas_usecase_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/don-aie-cohort8/aie8-s09-adv-retrieval/.venv/lib/python3.13/site-packages/ragas/testset/synthesizers/generate.py:164\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    160\u001b[39m \u001b[38;5;250m        \u001b[39m\u001b[33;03m\"\"\"An embedding client was not provided. Provide an embedding through the transforms_embedding_model parameter. Alternatively you can provide your own transforms through the `transforms` parameter.\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m     )\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transforms:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     transforms = \u001b[43mdefault_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms_llm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransforms_embedding_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# convert the documents to Ragas nodes\u001b[39;00m\n\u001b[32m    171\u001b[39m nodes = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/don-aie-cohort8/aie8-s09-adv-retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/default.py:160\u001b[39m, in \u001b[36mdefault_transforms\u001b[39m\u001b[34m(documents, llm, embedding_model)\u001b[39m\n\u001b[32m    153\u001b[39m     transforms = [\n\u001b[32m    154\u001b[39m         summary_extractor,\n\u001b[32m    155\u001b[39m         node_filter,\n\u001b[32m    156\u001b[39m         Parallel(summary_emb_extractor, theme_extractor, ner_extractor),\n\u001b[32m    157\u001b[39m         ner_overlap_sim,\n\u001b[32m    158\u001b[39m     ]\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDocuments appears to be too short (ie 100 tokens or less). Please provide longer documents.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m     )\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m transforms\n",
            "\u001b[31mValueError\u001b[39m: Documents appears to be too short (ie 100 tokens or less). Please provide longer documents."
          ]
        }
      ],
      "source": [
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "golden_dataset_attempt_1 = generator.generate_with_langchain_docs(ragas_usecase_data, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc 0: 39 tokens\n",
            "Doc 1: 38 tokens\n",
            "Doc 2: 37 tokens\n",
            "Doc 3: 40 tokens\n",
            "Doc 4: 40 tokens\n",
            "Doc 5: 38 tokens\n",
            "Doc 6: 41 tokens\n",
            "Doc 7: 38 tokens\n",
            "Doc 8: 38 tokens\n",
            "Doc 9: 45 tokens\n",
            "Doc 10: 44 tokens\n",
            "Doc 11: 39 tokens\n",
            "Doc 12: 41 tokens\n",
            "Doc 13: 36 tokens\n",
            "Doc 14: 44 tokens\n",
            "Doc 15: 42 tokens\n",
            "Doc 16: 35 tokens\n",
            "Doc 17: 41 tokens\n",
            "Doc 18: 37 tokens\n",
            "Doc 19: 39 tokens\n",
            "Doc 20: 41 tokens\n",
            "Doc 21: 40 tokens\n",
            "Doc 22: 37 tokens\n",
            "Doc 23: 33 tokens\n",
            "Doc 24: 39 tokens\n",
            "Doc 25: 37 tokens\n",
            "Doc 26: 38 tokens\n",
            "Doc 27: 36 tokens\n",
            "Doc 28: 37 tokens\n",
            "Doc 29: 41 tokens\n",
            "Doc 30: 42 tokens\n",
            "Doc 31: 36 tokens\n",
            "Doc 32: 41 tokens\n",
            "Doc 33: 41 tokens\n",
            "Doc 34: 38 tokens\n",
            "Doc 35: 34 tokens\n",
            "Doc 36: 41 tokens\n",
            "Doc 37: 44 tokens\n",
            "Doc 38: 39 tokens\n",
            "Doc 39: 40 tokens\n",
            "Doc 40: 41 tokens\n",
            "Doc 41: 39 tokens\n",
            "Doc 42: 39 tokens\n",
            "Doc 43: 40 tokens\n",
            "Doc 44: 43 tokens\n",
            "Doc 45: 40 tokens\n",
            "Doc 46: 37 tokens\n",
            "Doc 47: 42 tokens\n",
            "Doc 48: 40 tokens\n",
            "Doc 49: 39 tokens\n"
          ]
        }
      ],
      "source": [
        "# calculate the length in tokens of the source documents\n",
        "\n",
        "token_splitter = TokenTextSplitter()\n",
        "\n",
        "for i, doc in enumerate(ragas_usecase_data):\n",
        "    tokens = token_splitter._tokenizer.encode(doc.page_content)\n",
        "    print(f\"Doc {i}: {len(tokens)} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### using RAGAS Knowledge Graph functionality\n",
        "\n",
        "- unroll the golden testset process to have more control over generation\n",
        "- custom personas are not necessary but showcase useful RAGAS functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### create the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "kg = KnowledgeGraph()\n",
        "\n",
        "for doc in ragas_usecase_data:\n",
        "    kg.nodes.append(\n",
        "        Node(\n",
        "            type=NodeType.DOCUMENT,\n",
        "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 50, relationships: 0)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the initial graph\n",
        "\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6854d1e16d9470faf68e6ce8fa2abc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "895bd3b2c0d94a7182a1f5c8f0447d72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56524aa7053a4cadac2f9be486d9621a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying KeyphrasesExtractor:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Property 'keyphrases' already exists in node 'c2c497'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e76b3c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '677e26'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'da968f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd4b43d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ef0b58'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8d31aa'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8c2091'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e6aea8'. Skipping!\n",
            "Property 'keyphrases' already exists in node '8da5aa'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f61639'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'df7dc4'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'bde00c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '609339'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9bfc1a'. Skipping!\n",
            "Property 'keyphrases' already exists in node '117c60'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ec56c3'. Skipping!\n",
            "Property 'keyphrases' already exists in node '0b4de3'. Skipping!\n",
            "Property 'keyphrases' already exists in node '50d59b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '7c9f8e'. Skipping!\n",
            "Property 'keyphrases' already exists in node '488ef7'. Skipping!\n",
            "Property 'keyphrases' already exists in node '762ede'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'eaaa55'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd061a5'. Skipping!\n",
            "Property 'keyphrases' already exists in node '559737'. Skipping!\n",
            "Property 'keyphrases' already exists in node '93a3b7'. Skipping!\n",
            "Property 'keyphrases' already exists in node '93d8df'. Skipping!\n",
            "Property 'keyphrases' already exists in node '9891f6'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'a74b5d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd9cab0'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd8e1d7'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e03a3b'. Skipping!\n",
            "Property 'keyphrases' already exists in node '03f84f'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'f74fa0'. Skipping!\n",
            "Property 'keyphrases' already exists in node '7e2efa'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e8fb06'. Skipping!\n",
            "Property 'keyphrases' already exists in node '78d9f8'. Skipping!\n",
            "Property 'keyphrases' already exists in node '4cac70'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e4e20a'. Skipping!\n",
            "Property 'keyphrases' already exists in node '436f95'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'ae3dfb'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'e14771'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'd123bb'. Skipping!\n",
            "Property 'keyphrases' already exists in node '5cc3f0'. Skipping!\n",
            "Property 'keyphrases' already exists in node '65751c'. Skipping!\n",
            "Property 'keyphrases' already exists in node '122e01'. Skipping!\n",
            "Property 'keyphrases' already exists in node '15050d'. Skipping!\n",
            "Property 'keyphrases' already exists in node 'b08965'. Skipping!\n",
            "Property 'keyphrases' already exists in node '93bbe6'. Skipping!\n",
            "Property 'keyphrases' already exists in node '6f5f8c'. Skipping!\n"
          ]
        }
      ],
      "source": [
        "headline_extractor = HeadlinesExtractor(llm=generator_llm)\n",
        "headline_splitter = HeadlineSplitter(max_tokens=1500)\n",
        "keyphrase_extractor = KeyphrasesExtractor(llm=generator_llm)\n",
        "\n",
        "transforms = [\n",
        "    headline_extractor,\n",
        "    headline_splitter,\n",
        "    keyphrase_extractor\n",
        "]\n",
        "\n",
        "apply_transforms(kg, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 100, relationships: 0)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the graph after applying the transforms\n",
        "\n",
        "kg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KnowledgeGraph(nodes: 100, relationships: 0)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kg.save(\"usecase_data_kg.json\")\n",
        "usecase_data_kg = KnowledgeGraph.load(\"usecase_data_kg.json\")\n",
        "usecase_data_kg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### identify personas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Persona               | Use Case Type                             | Derived From                                                                |\n",
        "| --------------------- | ----------------------------------------- | --------------------------------------------------------------------------- |\n",
        "| Decision Analyst      | **Asking / Seeking Information**          | “Decision support and information interpretation dominate work-related use” |\n",
        "| Domain Researcher     | **Knowledge Graph & Multi-hop Retrieval** | Multi-domain structure in `Projects_with_Domains.csv`                       |\n",
        "| Instructional Creator | **Practical Guidance / Tutoring**         | Education & self-learning patterns (10% of usage)                           |\n",
        "| AI Practitioner       | **Evaluation & Coding Assistance**        | Work-related “Doing” messages (40% overall)                                 |\n",
        "| Creative Strategist   | **Self-Expression / Ideation**            | Growth of “Expressing” and “Creative Guidance” segments                     |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "persona_decision_analyst = Persona(\n",
        "    name=\"Decision Analyst\",\n",
        "    role_description=(\n",
        "        \"Uses AI for analytical reasoning and decision support. \"\n",
        "        \"Seeks data-driven insights, summaries, and structured outputs to inform business or policy decisions. \"\n",
        "        \"Values concise factual responses, traceable evidence, and cost-effective solutions.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_domain_researcher = Persona(\n",
        "    name=\"Domain Researcher\",\n",
        "    role_description=(\n",
        "        \"Explores multi-domain knowledge sources (e.g., education, health, finance, engineering). \"\n",
        "        \"Prefers context-rich retrieval with citations and nuanced synthesis. \"\n",
        "        \"Often asks cross-domain 'why/how' questions requiring reasoning beyond surface-level facts.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_instructional_creator = Persona(\n",
        "    name=\"Instructional Creator\",\n",
        "    role_description=(\n",
        "        \"Designs educational or training materials using AI. \"\n",
        "        \"Relies on clear, pedagogical explanations and consistent tone. \"\n",
        "        \"Frequently asks for examples, analogies, or simplified explanations for learners.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_ai_practitioner = Persona(\n",
        "    name=\"AI Practitioner\",\n",
        "    role_description=(\n",
        "        \"Implements and evaluates retrieval-augmented systems. \"\n",
        "        \"Needs structured, reproducible outputs like JSON schemas, test cases, and evaluation metrics. \"\n",
        "        \"Focuses on precision, recall, and factual grounding when comparing retrievers or datasets.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "persona_creative_strategist = Persona(\n",
        "    name=\"Creative Strategist\",\n",
        "    role_description=(\n",
        "        \"Uses AI for ideation, storytelling, and persuasive communication. \"\n",
        "        \"Seeks novel phrasing, emotional resonance, and creative reframing of ideas. \"\n",
        "        \"Frequently explores role-play or scenario-based reasoning.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "personas = [\n",
        "    persona_decision_analyst,\n",
        "    persona_domain_researcher,\n",
        "    persona_instructional_creator,\n",
        "    persona_ai_practitioner,\n",
        "    persona_creative_strategist,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### define query behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_distibution = [\n",
        "    (\n",
        "        SingleHopSpecificQuerySynthesizer(llm=generator_llm, property_name=\"headlines\"),\n",
        "        0.5,\n",
        "    ),\n",
        "    (\n",
        "        SingleHopSpecificQuerySynthesizer(\n",
        "            llm=generator_llm, property_name=\"keyphrases\"\n",
        "        ),\n",
        "        0.5,\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### generate testset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = TestsetGenerator(\n",
        "    llm=generator_llm,\n",
        "    embedding_model=generator_embeddings,\n",
        "    knowledge_graph=usecase_data_kg,\n",
        "    persona_list=personas,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4294fd6d3a44822852a2ed0aecc59ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0be411155512402eb1d87d7b2ca6ba0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How Security important in InsightAI project wi...</td>\n",
              "      <td>[Project Title: InsightAI 1\\nProject Domain: S...</td>\n",
              "      <td>The InsightAI project is focused on the domain...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Could you provide a detailed explanation of ho...</td>\n",
              "      <td>[Project Title: ShopSmart 2\\nProject Domain: D...</td>\n",
              "      <td>The ShopSmart 2 project falls under the second...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what WealthifyAI 3 do in medical imaging?</td>\n",
              "      <td>[Project Title: WealthifyAI 3\\nProject Domain:...</td>\n",
              "      <td>WealthifyAI 3 is a medical imaging solution th...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is MediMind 4 and how does it integrate a...</td>\n",
              "      <td>[Project Title: MediMind 4\\nProject Domain: E‑...</td>\n",
              "      <td>MediMind 4 is a project situated primarily in ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Could you explain the primary domain focus of ...</td>\n",
              "      <td>[Project Title: AutoMate 5\\nProject Domain: Fi...</td>\n",
              "      <td>The AutoMate 5 project primarily focuses on th...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          user_input  \\\n",
              "0  How Security important in InsightAI project wi...   \n",
              "1  Could you provide a detailed explanation of ho...   \n",
              "2          what WealthifyAI 3 do in medical imaging?   \n",
              "3  What is MediMind 4 and how does it integrate a...   \n",
              "4  Could you explain the primary domain focus of ...   \n",
              "\n",
              "                                  reference_contexts  \\\n",
              "0  [Project Title: InsightAI 1\\nProject Domain: S...   \n",
              "1  [Project Title: ShopSmart 2\\nProject Domain: D...   \n",
              "2  [Project Title: WealthifyAI 3\\nProject Domain:...   \n",
              "3  [Project Title: MediMind 4\\nProject Domain: E‑...   \n",
              "4  [Project Title: AutoMate 5\\nProject Domain: Fi...   \n",
              "\n",
              "                                           reference  \\\n",
              "0  The InsightAI project is focused on the domain...   \n",
              "1  The ShopSmart 2 project falls under the second...   \n",
              "2  WealthifyAI 3 is a medical imaging solution th...   \n",
              "3  MediMind 4 is a project situated primarily in ...   \n",
              "4  The AutoMate 5 project primarily focuses on th...   \n",
              "\n",
              "                       synthesizer_name  \n",
              "0  single_hop_specifc_query_synthesizer  \n",
              "1  single_hop_specifc_query_synthesizer  \n",
              "2  single_hop_specifc_query_synthesizer  \n",
              "3  single_hop_specifc_query_synthesizer  \n",
              "4  single_hop_specifc_query_synthesizer  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "golden_testset = generator.generate(testset_size=10, query_distribution=query_distibution)\n",
        "golden_testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PLEASE NOTE...\n",
        "\n",
        "- in the end the golden testset generation process still creates a graph with no edges\n",
        "- the concept of custom personas is still valuable and helps to design better systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OPTIONAL:   preserve the RAGAS golden testset as jsonl and hugging face datasets\n",
        "\n",
        "- demonstrating a few approaches to capture the dataset for later use (including versioning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "/tmp/ipykernel_10976/2832967315.py:93: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now  = datetime.utcnow().isoformat() + \"Z\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pushing to dwb2023/ragas-golden-testset-personas (private=False) ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4d0a2b3fe124f5196932d9ceab62e0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca429354b13c48848af01a209d567488",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "239b169818ed4499af3b89d5bbe21f32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "154bbf9fc60f4d12a0415d09677d2ccf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c3b42d819584bfabb9407e35959be4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Push complete. Verifying...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "853292e6014a4806b335076f0919a05d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "888417e0c05c43c78d20af34d68e783d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name'],\n",
            "        num_rows: 5\n",
            "    })\n",
            "})\n",
            "✅ Done (AS-IS schema, personas captured in dataset name).\n"
          ]
        }
      ],
      "source": [
        "# --- One-Cell Push (AS-IS RAGAS schema, README w/ notebook link, personas in name) ---\n",
        "\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "import getpass\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "\n",
        "from huggingface_hub import HfApi, login, upload_file\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "\n",
        "# =============== USER CONFIG ===============\n",
        "HF_USERNAME   = \"dwb2023\"\n",
        "DATASET_NAME  = \"ragas-golden-testset-personas\"  # captures personas concept\n",
        "REPO_ID       = f\"{HF_USERNAME}/{DATASET_NAME}\"\n",
        "PRIVATE       = False\n",
        "\n",
        "LICENSE       = \"apache-2.0\"\n",
        "TAGS          = [\"ragas\", \"golden-testset\", \"rag-eval\", \"personas\"]\n",
        "LANGS         = [\"en\"]\n",
        "\n",
        "# Validate the schema your RAGAS run actually produced (no renaming)\n",
        "REQUIRED_COLUMNS_AS_IS = {\"user_input\", \"reference\", \"reference_contexts\"}  # add others if present\n",
        "\n",
        "# Link to the generating notebook\n",
        "GENERATING_NOTEBOOK_URL = (\n",
        "    \"https://github.com/don-aie-cohort8/aie8-s09-adv-retrieval/blob/main/notebooks/session09-adv-retrieval-ragas.ipynb\"\n",
        ")\n",
        "\n",
        "PROVENANCE_NOTES = (\n",
        "    \"Generated via RAGAS golden testset pipeline (personas scenario). \"\n",
        "    \"See the linked notebook for full pipeline details.\"\n",
        ")\n",
        "# ==========================================\n",
        "\n",
        "# 0) Login (env var or prompt)\n",
        "token = os.environ.get(\"HUGGINGFACE_HUB_TOKEN\")\n",
        "if not token:\n",
        "    token = getpass.getpass(\"Enter your Hugging Face Hub Token: \")\n",
        "login(token=token)\n",
        "\n",
        "# 1) Ensure dataset repo exists\n",
        "api = HfApi()\n",
        "api.create_repo(repo_id=REPO_ID, repo_type=\"dataset\", private=PRIVATE, exist_ok=True)\n",
        "\n",
        "# 2) Convert to HF dataset (AS-IS)\n",
        "hf_ds = golden_testset.to_hf_dataset()  # Dataset or DatasetDict\n",
        "\n",
        "# 3) (Optional) JSONL for local inspection\n",
        "golden_testset.to_jsonl(\"golden_testset.jsonl\")\n",
        "\n",
        "# 4) Validate AS-IS schema\n",
        "def _assert_columns(ds, required):\n",
        "    present = set(ds.column_names)\n",
        "    missing = required - present\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}. Present: {sorted(present)}\")\n",
        "\n",
        "if isinstance(hf_ds, DatasetDict):\n",
        "    for _, ds in hf_ds.items():\n",
        "        _assert_columns(ds, REQUIRED_COLUMNS_AS_IS)\n",
        "else:\n",
        "    _assert_columns(hf_ds, REQUIRED_COLUMNS_AS_IS)\n",
        "\n",
        "# 5) Build README from real columns + notebook link\n",
        "def _fingerprint(ds_obj) -> str:\n",
        "    if isinstance(ds_obj, DatasetDict):\n",
        "        payload = {k: ds_obj[k].column_names for k in ds_obj.keys()}\n",
        "        payload[\"_sizes\"] = {k: len(ds_obj[k]) for k in ds_obj.keys()}\n",
        "    else:\n",
        "        payload = {\"columns\": ds_obj.column_names, \"rows\": len(ds_obj)}\n",
        "    return hashlib.sha256(json.dumps(payload, sort_keys=True).encode()).hexdigest()[:12]\n",
        "\n",
        "def _schema_list(ds_obj) -> List[str]:\n",
        "    if isinstance(ds_obj, DatasetDict):\n",
        "        cols = set()\n",
        "        for _, ds in ds_obj.items():\n",
        "            cols |= set(ds.column_names)\n",
        "        return sorted(cols)\n",
        "    return sorted(ds_obj.column_names)\n",
        "\n",
        "def _friendly_descriptions(cols: List[str]) -> Dict[str, str]:\n",
        "    hints = {\n",
        "        \"user_input\": \"The generated query/question for evaluation.\",\n",
        "        \"reference_contexts\": \"List of ground-truth passages used as reference context.\",\n",
        "        \"reference\": \"The expected/ground-truth answer.\",\n",
        "        \"synthesizer_name\": \"Name of the synthesizer that produced the sample.\",\n",
        "    }\n",
        "    return {c: hints.get(c, \"\") for c in cols}\n",
        "\n",
        "fp   = _fingerprint(hf_ds)\n",
        "now  = datetime.utcnow().isoformat() + \"Z\"\n",
        "cols = _schema_list(hf_ds)\n",
        "desc = _friendly_descriptions(cols)\n",
        "\n",
        "schema_md = \"\\n\".join([f\"- **{c}**: {desc[c]}\" if desc[c] else f\"- **{c}**\" for c in cols])\n",
        "required_md = \", \".join(sorted(REQUIRED_COLUMNS_AS_IS))\n",
        "\n",
        "readme = f\"\"\"---\n",
        "dataset_info:\n",
        "  pretty_name: \"RAGAS Golden Testset (Personas, AS-IS Schema)\"\n",
        "  task_categories: [\"question-answering\"]\n",
        "  license: \"{LICENSE}\"\n",
        "  language: {json.dumps(LANGS)}\n",
        "  tags: {json.dumps(TAGS)}\n",
        "---\n",
        "\n",
        "# RAGAS Golden Testset — Personas (AS-IS)\n",
        "\n",
        "- **Generated**: {now}\n",
        "- **Repo**: `{REPO_ID}`\n",
        "- **Fingerprint**: `{fp}`\n",
        "- **Provenance**: {PROVENANCE_NOTES}\n",
        "- **Generating Notebook**: {GENERATING_NOTEBOOK_URL}\n",
        "\n",
        "## Schema (as produced by RAGAS)\n",
        "{schema_md}\n",
        "\n",
        "**Required columns validated in notebook:** {required_md}\n",
        "\n",
        "> Note: `reference_contexts` is intentionally kept as a list to reflect the native RAGAS output for teaching.\n",
        "\"\"\"\n",
        "\n",
        "upload_file(\n",
        "    path_or_fileobj=readme.encode(\"utf-8\"),\n",
        "    path_in_repo=\"README.md\",\n",
        "    repo_id=REPO_ID,\n",
        "    repo_type=\"dataset\",\n",
        ")\n",
        "\n",
        "# 6) Push and verify\n",
        "print(f\"Pushing to {REPO_ID} (private={PRIVATE}) ...\")\n",
        "hf_ds.push_to_hub(REPO_ID, private=PRIVATE)\n",
        "print(\"Push complete. Verifying...\")\n",
        "loaded = load_dataset(REPO_ID)\n",
        "print(loaded)\n",
        "print(\"✅ Done (AS-IS schema, personas captured in dataset name).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
